# rag-chatbot-springboot-langchain4j-azure-openai

Retrieval-Augmented Generation (RAG) is revolutionizing how we build intelligent applications by combining the reasoning power of Large Language Models (LLMs) with custom, domain-specific knowledge bases. This project demonstrates how to build a document-aware chatbot using:  

- Spring Boot for scalable backend architecture
- LangChain4j for agentic AI orchestration
- Azure OpenAI for embedding and chat completion
- Vector stores for semantic search and retrieval

The chatbot can ingest documents (PDF, DOCX), extract meaningful content, and answer user queries using context-aware responses powered by RAG.  

Prerequisites: 
- Java 25,  Maven,  Docker Compose, Azure OpenAI access (embedding + chat models)
